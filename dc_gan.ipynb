{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集的位置\n",
    "avatar_img_path = \"./data\"\n",
    "\n",
    "import imageio\n",
    "import os\n",
    "import numpy as np\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    加载数据集\n",
    "    :return: 返回numpy数组\n",
    "    \"\"\"\n",
    "    all_images = []\n",
    "    for image_name in os.listdir(avatar_img_path):\n",
    "        image =  imageio.imread(os.path.join(avatar_img_path,image_name))\n",
    "        all_images.append(image)\n",
    "    all_images = np.array(all_images)\n",
    "    # 将图片数值变成[-1,1]\n",
    "    all_images = (all_images - 127.5) / 127.5\n",
    "    # 将数据随机排序\n",
    "    np.random.shuffle(all_images)\n",
    "    return all_images\n",
    "img_dataset = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def show_images(images,index = -1):\n",
    "    \"\"\"\n",
    "    展示并保存图片\n",
    "    :param images: 需要show的图片\n",
    "    :param index: 图片名\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    for i, image in enumerate(images):\n",
    "        ax = plt.subplot(5, 5, i+1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(image)\n",
    "    plt.savefig(\"data_%d.png\"%index)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_images(img_dataset[0: 25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise的维度\n",
    "noise_dim = 100\n",
    "# 图片的shape\n",
    "image_shape = (64,64,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D, Dense, BatchNormalization, LeakyReLU, Input,Reshape, MaxPooling2D, Flatten, AveragePooling2D, Conv2DTranspose\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_G():\n",
    "    \"\"\"\n",
    "    构建生成器\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    # 全连接层 100 -> 2048\n",
    "    model.add(Dense(2048,input_dim = noise_dim))\n",
    "    # 激活函数\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    # 全连接层 2048 ->  8 * 8 * 256\n",
    "    model.add(Dense(8 * 8 * 256))\n",
    "    # DN层\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    # 8 * 8 * 256 -> (8,8,256)\n",
    "    model.add(Reshape((8, 8, 256)))\n",
    "    # 卷积层 (8,8,256) -> (8,8,128)\n",
    "    model.add(Conv2D(128, kernel_size=5, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    # 反卷积层 (8,8,128) -> (16,16,128)\n",
    "    model.add(Conv2DTranspose(128, kernel_size=5, strides=2, padding='same'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    # 反卷积层 (16,16,128) -> (32,32,64)\n",
    "    model.add(Conv2DTranspose(64, kernel_size=5, strides=2, padding='same'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    # 反卷积层  (32,32,64) -> (64,64,3) = 图片\n",
    "    model.add(Conv2DTranspose(3, kernel_size=5, strides=2, padding='same', activation='tanh'))\n",
    "    return model\n",
    "G = build_G()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_D():\n",
    "    \"\"\"\n",
    "    构建判别器\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    # 卷积层\n",
    "    model.add(Conv2D(64, kernel_size=5, padding='valid',input_shape = image_shape))\n",
    "    # BN层\n",
    "    model.add(BatchNormalization())\n",
    "    # 激活层\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    # 平均池化层\n",
    "    model.add(AveragePooling2D(pool_size=2))\n",
    "    # 卷积层\n",
    "    model.add(Conv2D(128, kernel_size=3, padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(AveragePooling2D(pool_size=2))\n",
    "    model.add(Conv2D(256, kernel_size=3, padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(AveragePooling2D(pool_size=2))\n",
    "    # 将输入展平\n",
    "    model.add(Flatten())\n",
    "    # 全连接层\n",
    "    model.add(Dense(1024))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    # 最终输出1(true img) 0(fake img)的概率大小\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(learning_rate=0.0002, beta_1=0.5))\n",
    "    return model\n",
    "D = build_D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_gan():\n",
    "    \"\"\"\n",
    "    构建GAN网络\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 冷冻判别器，也就是在训练的时候只优化G的网络权重，而对D保持不变\n",
    "    D.trainable = False\n",
    "    # GAN网络的输入\n",
    "    gan_input = Input(shape=(noise_dim,))\n",
    "    # GAN网络的输出\n",
    "    gan_out = D(G(gan_input))\n",
    "    # 构建网络\n",
    "    gan = Model(gan_input,gan_out)\n",
    "    # 编译GAN网络，使用Adam优化器，以及加上交叉熵损失函数（一般用于二分类）\n",
    "    gan.compile(loss='binary_crossentropy',optimizer=Adam(learning_rate=0.0002, beta_1=0.5))\n",
    "    return gan\n",
    "GAN = build_gan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sample_noise(batch_size):\n",
    "    \"\"\"\n",
    "    随机产生正态分布（0，1）的noise\n",
    "    :param batch_size:\n",
    "    :return: 返回的shape为(batch_size,noise)\n",
    "    \"\"\"\n",
    "    return np.random.normal(size=(batch_size, noise_dim))\n",
    "\n",
    "def smooth_pos_labels(y):\n",
    "    \"\"\"\n",
    "    使得true label的值的范围为[0.7,1.2]\n",
    "    :param y:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return y - 0.3 + (np.random.random(y.shape) * 0.5)\n",
    "\n",
    "def smooth_neg_labels(y):\n",
    "    \"\"\"\n",
    "    使得fake label的值的范围为[0.0,0.3]\n",
    "    :param y:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return y + np.random.random(y.shape) * 0.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_batch(data, batch_size,index):\n",
    "    \"\"\"\n",
    "    按批次加载图片\n",
    "    :param data: 图片数据集\n",
    "    :param batch_size: 批次大小\n",
    "    :param index: 批次序号\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return data[index*batch_size: (index+1)*batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(epochs=100, batch_size=64):\n",
    "    \"\"\"\n",
    "    训练函数\n",
    "    :param epochs: 训练的次数\n",
    "    :param batch_size: 批尺寸\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 判别器损失\n",
    "    discriminator_loss = 0\n",
    "    # 生成器损失\n",
    "    generator_loss = 0\n",
    "    # img_dataset.shape[0] / batch_size 代表这个数据可以分为几个批次进行训练\n",
    "    n_batches = int(img_dataset.shape[0] / batch_size)\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        for index in range(n_batches):\n",
    "            # 按批次加载数据\n",
    "            x = load_batch(img_dataset, batch_size,index)\n",
    "            # 产生noise\n",
    "            noise = sample_noise(batch_size)\n",
    "            # G网络产生图片\n",
    "            generated_images = G.predict(noise)\n",
    "            # 产生为1的标签\n",
    "            y_real = np.ones(batch_size)\n",
    "            # 将1标签的范围变成[0.7 , 1.2]\n",
    "            y_real = smooth_pos_labels(y_real)\n",
    "            # 产生为0的标签\n",
    "            y_fake = np.zeros(batch_size)\n",
    "            # 将0标签的范围变成[0.0 , 0.3]\n",
    "            y_fake = smooth_neg_labels(y_fake)\n",
    "            # 训练真图片loss\n",
    "            d_loss_real = D.train_on_batch(x, y_real)\n",
    "            # 训练假图片loss\n",
    "            d_loss_fake = D.train_on_batch(generated_images, y_fake)\n",
    "\n",
    "            discriminator_loss = d_loss_real + d_loss_fake\n",
    "            # 产生为1的标签\n",
    "            y_real = np.ones(batch_size)\n",
    "            # 训练GAN网络，input = fake_img ,label = 1\n",
    "            generator_loss = GAN.train_on_batch(noise, y_real)\n",
    "        \n",
    "        print('[Epoch {0}]. Discriminator loss : {1}. Generator_loss: {2}.'.format(i, discriminator_loss, generator_loss))\n",
    "        # 随机产生(25,100)的noise\n",
    "        test_noise = sample_noise(25)\n",
    "        # 使用G网络生成25张图偏\n",
    "        test_images = G.predict(test_noise)\n",
    "        # show 预测 img\n",
    "        show_images(test_images,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train(epochs=50, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1594283445949",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}